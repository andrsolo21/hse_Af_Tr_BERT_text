%!TEX TS-program = xelatex

% Шаблон документа LaTeX создан в 2018 году
% Алексеем Подчезерцевым
% В качестве исходных использованы шаблоны
% 	Данилом Фёдоровых (danil@fedorovykh.ru) 
%		https://www.writelatex.com/coursera/latex/5.2.2
%	LaTeX-шаблон для русской кандидатской диссертации и её автореферата.
%		https://github.com/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template

\documentclass[a4paper,14pt]{article}

\input{data/preambular.tex}
\begin{document} % конец преамбулы, начало документа
	 \input{data/title.tex}
	
	\tableofcontents
	
	\pagebreak
	%\section{Индивидуальное задание}
	
	%\pagebreak
	
	%-
	
	%\pagebreak
	
	%\section{Дневник практики}
	
	%\pagebreak
	
	%-
	
	%\pagebreak
	
	
	\section{Введение}
	
	Целью данной работы является исследование и измерение качества аффинных преобразований для модели BERT.
	
	Для достижения поставленной цели необходимо решить следующие задачи:
	
	\begin{itemize}
	
		\item Исследование моделей векторного представления слов;
		
		\item Исследование методов оценки аффинных преобразований;
		
		\item Постановка задачи пропорциональной аналогии в терминах аффинного преобразования;
		
		\item Разработка метода оценки точности параллельного переноса для контекстуализированных моделей;
		
		\item Подготовка экспериментальных данных;
		
		\item Проведение экспериментов;
		
		\item Оценка полученных результатов.
		
	\end{itemize}

	Исследование проводится на языке python в среде Jupyter Notebok при использовании Google Colab. Jupyter Notebok является наиболее удобной платформой для проведения исследований на python.
	Google Colab является бесплатной и мощной платформой для запуска кода.
	При этом дается 12Гб оперативной памяти, доступ к Google диску для доступа к данным, а также есть возможность запускать код с использованием GPU.
	
	\pagebreak
	\section{Содержательная часть}
	
	\subsection{Описание профессиональных задач студента}
	
	Исследование моделей векторного представления слов;
	
	Исследование методов оценки афинных преобразований;
	
	Постановка задачи пропорциональной аналогии в терминах аффинного преобразования;
	
	Разработка метода оценки точности параллельного переноса для контекстуализированных моделей;
	
	Подготовка экспериментальных данных;
	
	Проведение экспериментов;
	
	Оценка полученных результатов.
	
	\subsection{Описание выполнения пунктов}
	
	\subsubsection{Исследование моделей векторного представления слов}
	1
	
	\subsubsection{Исследование методов оценки аффинных преобразований}
	2
	
	\subsubsection{Постановка задачи пропорциональной аналогии в терминах аффинного преобразования}
	3
	
	\subsubsection{Разработка метода оценки точности параллельного переноса для контекстуализированных моделей}
	4
	
	\subsubsection{Подготовка экспериментальных данных}
	
	Для получения эмбеддингов слов были взяты тексты из электронной библиотеки КиберЛенинка.
	Тексты двух жанров: литература и политика.
	
	Для оценки качества аффинных преобразований используется датасет $Google analogy test set$.
	Данный датасет был переведен на русский язык с сохранением семантических отношений между словами.
	Не все слова из данного датасета есть в словаре BERT, поэтому часть отношений пришлось убрать.
	
	\subsubsection{Проведение экспериментов}
	
	Для проведения экспериментов используется язык программирования python в среде Jupyter Notebok с использованием Google Colab.
	Jupyter Notebok является наиболее удобной платформой для проведения исследований на python.
	Google Colab является бесплатной и мощной платформой для запуска кода.
	При этом дается 12Гб оперативной памяти, доступ к Google диску для доступа к данным, а также есть возможность запускать код с использованием GPU.
	В качестве фреймворка для работы с моделью BERT был выбран pytorch, так как это современная и гибкая библиотека для работы с глубинным обучением.
	
	Для проведения экспериментов необходимо подготовить данные для их обработки в модели BERT.
	Сначала весь текст разбивается на отдельные предложения, далее происходит их токенизация и индексация.
	На этом этапе обработанные предложения по-одному отправляются в модель BERT.
	Данным способом обработаны по 1 миллиону предложений для каждого жанра.
	
	Полученные после обработки объекты представляют из себя четырёхразмерные тензоры, где оси отражают следующую информацию (в скобках представлено количество элементов):
	
	\begin{enumerate}
		
		\item Номер слоя (13 слоев);
		
		\item Номер батча (1 предложение);
		
		\item Количество слов/токенов в предложении (количество токенов в предложении);
		
		\item Векторное представление (768 свойств).

	\end{enumerate}	

	По оси слоев первый слой - это эмбеддинг, поступающий на вход модели, остальные 12 слоев отображают выходы 12 энкодеров.
	Номер батча в нашем случае не важен, так как используется только одно предложение.
	Следующая ось отображает токены в предложении с сохранением порядка.
	Последняя ось отвечает за векторное представление каждого токена.
	
	Получить итоговое векторное представление для токена можно несколькими способами (рисунок \ref{fig:dif_vars_get_v}).
	В нашем случае используется способ с суммированием последних четырех слоев, данный способ показывает хорошее качество.
	Способ с конкатенацией последних четырех не используется, так как он требует в 4 раза больше ресурсов.
	
	Описанным ранее методом обрабатываются все подготовленные предложения.
	Обработка происходит пачками по 10 тысяч предложений.
	Векторные представления токенов каждой пачки сохраняются на Google диск.
	Сделано это из-за ограничений оперативной памяти устройства.
	
	После того как получены векторные представления для всего текста, считаются средние эмбеддинги для всех токенов.
	Из-за ограничений оперативной памяти нельзя посчитать сразу все векторные представления, поэтому они считаются порциями с сохранением промежуточных результатов.
	
	Далее проверялось семантические отношения полученных эмбеддингов на переведенном датасете $Google analogy test set$.
	
	\subsubsection{Оценка полученных результатов}
	
	На рисунках \ref{fig:liter} и \ref{fig:politics} представлены результаты 

	
	
	\pagebreak
	\section{Заключение}
	
	%В ходе практики, был изучен принцип работы сверточной нейронной сети,  рассмотрены самые популярные архитектуры сверточных нейронных сетей и подходы к их обучению.
	
	%Были приобретены навыки по поиску необходимого датасета, по работе со сверточными нейронными сетями, их дообучению и применению в реальном приложении.
	%Помимо этого, были получены навыки по работе с графическим интерфейсом в python.
	
	%По окончанию практики была достигнута главная цель - применение теоретических знаний, полученных в процессе обучения, при решении реальных задач.
	
	%А также приобретены навыки и опыт практической работы.
	%Данная практика является хорошим практическим опытом для дальнейшей самостоятельной деятельности.
	
	\pagebreak
	\section{Приложения}
	
	С кодом можно ознакомиться по ссылке:

 \href{https://github.com/andrsolo21/hse_Af_Tr_BERTn}{https://github.com/andrsolo21/hse\_Af\_Tr\_BERT}.
	

	
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{image/irvrsv9mefroz7io6ilnjng3fo4}
	\caption{Возможные варианты получения векторного представления}
	\label{fig:dif_vars_get_v}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{image/liter}
	\caption{Результаты тестирования для текста с литературой}
	\label{fig:liter}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{image/politics}
	\caption{Результаты тестирования для текста с политикой}
	\label{fig:politics}
\end{figure}


	%\newpage 
	%\renewcommand{\refname}{{\normalsize Список использованных источников}} 
	%\centering 
	%\begin{thebibliography}{9} 
	%	\addcontentsline{toc}{section}{\refname} 
	%	\bibitem{Verilog} Thomas D., Moorby P. The Verilog Hardware Description Language. – Springer Science \& Business Media, 2008.
	%	\bibitem{Quartus} Антонов А., Филиппов А., Золотухо Р. Средства системной отладки САПР Quartus II //Компоненты и технологии. – 2008. – №. 89.
	%\end{thebibliography}
	
\end{document} % конец документа